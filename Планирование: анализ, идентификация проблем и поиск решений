Существующие проблемы:
    Общими словами:
        1. Задержка выполнения заказов.
        2. Неспособность выдержать нагрузку при использовании API внешними системами.
        3. Высокая задержка при загрузке MES - операторам сложно получить актуальную на момент времени информацию о новых заказах.
        4. Недостаточная эффективность процесса тестирования:
            4.1 Нехватка QA-персонала
            4.2 Отсутствие автоматизированных тестов
            4.3 Отсутствие нагрузочного тестирования
            4.4 Увеличение задержек из-за дефектов уровня high или highest наводят 
                на мысль об отсутствии должного качества unit-тестирования разработчиками
        5. Отсутствие адекватной реакции на возникающие технические проблемы
            5.1 Отсутствие в штате SRE
            5.2 Нехватка наблюдаемости системы как ее качества
        6. Все сервисы запрашивают "живые" данные из баз данных, что увеличивает на них нагрузку

    Техническое описание проблемы:
        1. Единые базы для чтения/записи каждого сервиса
            1.1 Единая точка отказа
            1.2 Вся нагрузка падает на единственный инстанс 
        2. Единственный инстанс сервиса Internet Shop / Shop API
            2.1 Единая точка отказа
            2.2 Неспособность подстраиваться под увеличение нагрузки
        3. Единственный инстанс сервиса CRM / CRM API
            3.1 Единая точка отказа
            3.2 Неспособность подстраиваться под увеличение нагрузки
        4. Единственный инстанс сервиса MES / MES API
            4.1 Единая точка отказа
            4.2 Неспособность подстраиваться под увеличение нагрузки
        5. Отсутствие централизованной системы наблюдения за системой: метрики, алерты, трейсинг
        6. Сложная система раскатки на предпрод/прод, препятствующая адекватной реакции системы на возрастающую нагрузку:
            6.1 Отсутствие CI/CD процесса - нет возможности "нажать на кнопку" чтобы выполнить релиз
            6.2 Как следствие - масштабирование под увеличением нагрузки требует чрезмерных усилий 
                и большое количество ручного труда
            6.3 Предположительная потребность в полной остановке prod стенда для установки релиза, т.к.
                сервера занимают порты на машинах и в ручном режиме решать эту проблему без остановки сервиса
                кажется невозможным
        7. Межсервисное взаимодействие негибкое: сервисы по причине отсутствия реестра сервисов вынуждены
            обращаться друг к другу напрямую, что также мешает масштабированию системы


Первые три инициативы абсолютно необходимы, потому что позволят бизнесу решить уже существующие проблемы, а так же
    идентифицировать те, о которых сейчас имеется лишь смутное представление.
За полгода система обогатится:
    1. ELK stack
    2. Prometheus + Grafana
    3. Jaeger
    4. Redis
Каждая из технологий имеет довольно низкий порог вхождения и легкую начальную установку и конфигурацию. По мере
    выявления проблем, конечно, необходимо будет производить какой-то тюнинг, но чем раньше начнется
    эксплуатация, тем раньше можно будет проблемы обнаружить и решить.

Предлагаемые инициативы в порядке значимости (первые 3 - абсолютно необходимы для выживания):
    1. Внедрение системы мониторинга и трейсинга: поднятие Prometheus + Grafana + Jaeger и подключение к ним сервисов
        Наблюдаемость системы является ключевым фактором для принятия любых решений о её изменении - 
            только при достаточном количестве информации о конкретных технических проблемах имеется
            возможность адекватной реакции на происходящие изменения. 
        Сразу после появления метрик появится возможность проверить сформированные гипотезы об источниках
            проблем в системе. 
        После внедрения трейсинга появится возможность решить как B2B, так и B2C проблемы с восстановлением
            цепочки состояний заказа и поиска источника задержек его обработки. 
        Также необходим найм (минимум) второго девопса.
    2. Поставить Redis между MES API и MES DB:
        Оператор заинтересован в быстром получении заказа, что предполагает постоянно открытое окно браузера/приложения
            и ожидание этого нового заказа, что генерирует нагрузку на чтение в базу данных. 
        Если обработанное сообщение из RabbitMQ класть сначала в Redis, а затем по стратегии Write-Behind из него писать в БД, 
            то нагрузка упадет на кеш, что улучшит отклик системы для пользователя и одновременно снизит 
            количество запросов на запись в БД.
    3. Внедрение автоматизированного тестирования для проведения регресса типовых кейсов системы
        Система страдает от увеличения срока поставки релиза, что вполне возможно негативно сказывается 
            на работу бизнеса. Имеющийся QA-инженер имеет желание перехода в AQA и это желание можно эксплуатировать,
            но для безболезненного перехода требуется найм замены ему. Также если увеличение сроков поставки 
            действительно влечет за собой убытки для бизнеса, то штат увеличить надо более чем на одного инженера.

    --------

    4. Регулярное нагрузочное тестирование на preprod контуре
        Позволит на ранних этапах понимать узкие места системы и перенаправлять начатый процесс развития системы.
    
    5. Настройка CI/CD для удобного и надежного деплоя сервисов на preprod/prod
        CI/CD для dev стенда уже имеется, поэтому добавление джоб для preprod/prod контуров не будет трудозатратным,
            зато положит начало развитию системы в сторону ее масштабируемости. 
    
    6. Внедрение Service Registry системы (например, Consul) и замена прямого обращения сервисов друг к другу 
        на обращение по предоставленному Service Registry адресу.
            После появления CI/CD появится возможность и соблазн увеличивать количество инстансов приложения, 
                что создает необходимость роутинга их взаимодействия.

    7. Подключение SonarQube для повышения качества тестирования кода и выработка требований на процент покрытия тестами кода
        Упомянутая проблема увеличения времени поставок по причине наличия останавливающих факторов(баги уровня high или highest)
            говорит о плохом качестве поставляемого кода - указано, что unit-тесты пишутся, но, очевидно, пишутся плохо 
            (либо не пишутся вовсе)
    
    8. Разделение MES API на две части - выделить расчет стоимости по модели в отдельный сервис
        Одна из гипотез о плохом опыте взаимодействия с MES API - его высоконагруженность. Сервис одновременно обрабатывает запросы 
            пользователей через API, делает расчет стоимости и обрабатывает события из RabbitMQ. Отсутствие улучшения
            опыта после внедрения пагинации и фильтрации подсказывает, что проблема может крыться как раз в нехватке ресурсов на 
            все области применения сервиса. Разделение позволит более точечно управлять ресурсами.
        Разделение не выделено в качестве первого приоритета только потому, что без метрик невозможно сказать окупится ли
            затраченное на разделение время. В случае, если метрики подтверждают проблему, этот пункт становится критичным и 
            заменяет собой внедрение автотестов.  
    9. Внедрение kubernetes + istio
        Любая зрелая система должна использовать существующие удобства управления микросервисами. Последовательное решение предыдущих
        пунктов откладывает инициативу в долгосрок. 
    10. Кластеризация баз данных
        Проблем на базе не выявлено, без метрик строить какие-либо гипотезы невозможно. В штате нет DBA, которому можно было бы поручить
        фоном заниматься кластеризацией и настройкой балансировщика. Если компания обладает бюджетом для найма опытного сотрудника 
        (и оплаты найма внешними подрядчиками, т.к. самостоятельно компетенцию оценить нет возможности), то лучше его конечно нанять
        и параллельно любым изменениям приводить систему хранения в порядок: как минимум, поднять хотя бы по одной реплике каждой БД
        и разделить роли на запись и чтение.